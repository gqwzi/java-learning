
## [原文1](https://www.cnblogs.com/wanly3643/p/3904681.html)
## [原文2](https://www.jianshu.com/p/9d2c706e45b7)
## [原文3](https://www.jianshu.com/p/95cb570c8187) 

#  一种特别的BlockingQueue：SynchronousQueue

SynchronousQueue是一种很特别的BlockingQueue，

作为BlockingQueue中的一员，SynchronousQueue与其他BlockingQueue有着不同特性：

- SynchronousQueue没有容量。与其他BlockingQueue不同，
SynchronousQueue是一个不存储元素的BlockingQueue。
每一个put操作必须要等待一个take操作，否则不能继续添加元素，反之亦然。

- 因为没有容量，所以对应 peek, contains, clear, isEmpty ... 等方法其实是无效的。
例如clear是不执行任何操作的，contains始终返回false,peek始终返回null。

- SynchronousQueue分为公平和非公平，默认情况下采用非公平性访问策略，
当然也可以通过构造函数来设置为公平性访问策略（为true即可）。

- 若使用 TransferQueue, 则队列中永远会存在一个 dummy node（这点后面详细阐述）。

SynchronousQueue非常适合做交换工作，生产者的线程和消费者的线程同步以传递某些信息、事件或者任务。

 

任何一个添加元素的操作都必须等到另外一个线程拿走元素才会结束。
也就是SynchronousQueue本身不会存储任何元素，相当于生产者和消费者手递手直接交易。

## SynchronousQueue
与其他BlockingQueue一样，SynchronousQueue同样继承AbstractQueue和实现BlockingQueue接口：
```java
public class SynchronousQueue<E> extends AbstractQueue<E>
    implements BlockingQueue<E>, java.io.Serializable {
    }
```

SynchronousQueue有一个fair选项，如果fair为true，称为fair模式，否则就是unfair模式。

在fair模式下，所有等待的生产者线程或者消费者线程会按照开始等待时间依次排队，
然后按照等待先后顺序进行匹配交易。这种情况用队列实现。

在unfair模式下，则刚好相反，后来先匹配，这种情况用栈实现。

```java
    */
    public SynchronousQueue(boolean fair) {
        transferer = fair ? new TransferQueue() : new TransferStack();
    }
```    

SynchronousQueue提供了两个构造函数：
```java
public SynchronousQueue() {
        this(false);
    }

    public SynchronousQueue(boolean fair) {
        // 通过 fair 值来决定公平性和非公平性
        // 公平性使用TransferQueue，非公平性采用TransferStack
        transferer = fair ? new TransferQueue<E>() : new TransferStack<E>();
    }
``` 
TransferQueue、TransferStack继承Transferer，Transferer为SynchronousQueue的内部类，
它提供了一个方法transfer()，该方法定义了转移数据的规范，如下：
```java
  abstract static class Transferer<E> {
        abstract E transfer(E e, boolean timed, long nanos);
    }
```

transfer()方法主要用来完成转移数据的，如果e != null，相当于将一个数据交给消费者，
如果e == null，则相当于从一个生产者接收一个消费者交出的数据。

SynchronousQueue采用队列TransferQueue来实现公平性策略，
采用堆栈TransferStack来实现非公平性策略，他们两种都是通过链表实现的，
其节点分别为QNode，SNode。
TransferQueue和TransferStack在SynchronousQueue中扮演着非常重要的作用，
SynchronousQueue的put、take操作都是委托这两个类来实现的。

因为添加元素和拿走元素是类似手递手交易的，所以对于拿走元素和添加元素操作，
SynchronousQueue调用的是Transferer同一个方法transfer。

当object为null时表示是拿走元素，用于消费者线程，否则则是添加元素，用于生产者线程。
因此transfer方法是分析的重点。

## TransferQueue

TransferQueue是实现公平性策略的核心类，其节点为QNode，其定义如下：

```java
static final class TransferQueue<E> extends Transferer<E> {
        /** 头节点 */
        transient volatile QNode head;
        /** 尾节点 */
        transient volatile QNode tail;
        // 指向一个取消的结点
        //当一个节点中最后一个插入时，它被取消了但是可能还没有离开队列
        transient volatile QNode cleanMe;

        /**
         * 省略很多代码O(∩_∩)O
         */
    }

```
首先来看用于fair模式的TransferQueue的transfer方法：

看代码之前，来理一下逻辑：

1. 开始队列肯定是空。

2. 线程进入队列，如果队列是空的，那么就添加该线程进入队列，
然后进行等待（要么有匹配线程出现，要么就是该请求超时取消）

3. 第二个线程进入，如果前面一个线程跟它属于不同类型，
也就是说两者是可以匹配的，那么就从队列删除第一个线程。

    如果是相同的线程，那么做法参照2。


###  公平模式 TransferQueue
```java

/**
 *  这是一个非常典型的 queue , 它有如下的特点
 *  1. 整个队列有 head, tail 两个节点
 *  2. 队列初始化时会有个 dummy 节点
 *  3. 这个队列的头节点是个 dummy 节点/ 或 哨兵节点, 所以操作的总是队列中的第二个节点(AQS的设计中也是这也)
 */

/** 头节点 */
transient volatile QNode head;
/** 尾节点 */
transient volatile QNode tail;
/**
 * Reference to a cancelled node that might not yet have been
 * unlinked from queue because it was last inserted node
 * when it was cancelled
 */
/**
 * 对应 中断或超时的 前继节点,这个节点存在的意义是标记, 它的下个节点要删除
 * 何时使用:
 *      当你要删除 节点 node, 若节点 node 是队列的末尾, 则开始用这个节点,
 * 为什么呢？
 *      大家知道 删除一个节点 直接 A.CASNext(B, B.next) 就可以,但是当  节点 B 是整个队列中的末尾元素时,
 *      一个线程删除节点B, 一个线程在节点B之后插入节点 这样操作容易致使插入的节点丢失, 这个cleanMe很像
 *      ConcurrentSkipListMap 中的 删除添加的 marker 节点, 他们都是起着相同的作用
 */
transient volatile QNode cleanMe;

TransferQueue(){
    /**
     * 构造一个 dummy node, 而整个 queue 中永远会存在这样一个 dummy node
     * dummy node 的存在使得 代码中不存在复杂的 if 条件判断
     */
    QNode h = new QNode(null, false);
    head = h;
    tail = h;
}

/**
 * 推进 head 节点,将 老节点的 oldNode.next = this, help gc,
 * 这种和 ConcurrentLinkedQueue 中一样
 */
void advanceHead(QNode h, QNode nh){
    if(h == head && unsafe.compareAndSwapObject(this, headOffset, h, nh)){
        h.next = h; // forget old next help gc
    }
}

/** 更新新的 tail 节点 */
void advanceTail(QNode t, QNode nt){
    if(tail == t){
        unsafe.compareAndSwapObject(this, tailOffset, t, nt);
    }
}

/** CAS 设置 cleamMe 节点 */
boolean casCleanMe(QNode cmp, QNode val){
    return cleanMe == cmp && unsafe.compareAndSwapObject(this, cleanMeOffset, cmp, val);
}

```

从代码中我们知道, TransferQueue 是个 dual queue, 初始化时默认会个一个 dummy node;
而最特别的是 cleanMeNode, cleanMeNode是一个标记节点,
 cleanMeNode.next 节点是因中断或超时需要删除的节点，是在清除 队列最尾端节点时, 
 不直接删除这个节点, 而是间删除节点的前继节点标示为 cleanMe 节点, 
 为下次删除做准备, 功能和 ConcurrentSkipListMap 中的 marker 节点差不多, 
 都是防止在同一地点插入节点的同时因删除节点而造成节点的丢失, 
 不明白的可以看 [ConcurrentSkipListMap](https://www.jianshu.com/p/edc2fd149255).

 

### 公平模式 TransferQueue transfer方法
这个方法的主逻辑:

1. 若队列为空 / 队列中的尾节点和自己的 类型相同, 则添加 node
   到队列中, 直到 timeout/interrupt/其他线程和这个线程匹配
   timeout/interrupt awaitFulfill方法返回的是 node 本身
   匹配成功的话, 要么返回 null (producer返回的), 或正真的传递值 (consumer 返回的)

2. 队列不为空, 且队列的 head.next 节点是当前节点匹配的节点,
   进行数据的传递匹配, 并且通过 advanceHead 方法帮助 先前 block 的节点 dequeue
 

理清了基本逻辑，也就是会有两种情况：

1. 队列为空或者队列中的等待线程是相同类型

2. 队列中的等待线程是匹配的类型

```java

        Object transfer(Object e, boolean timed, long nanos) {

            QNode s = null;
            // e不是null表示是生成者线程，e就是产品，反之就是消费者线程
            boolean isData = (e != null);

            for (;;) {
                QNode t = tail;
                QNode h = head;
                // tail和head在队列创建时会被初始化成一个虚拟节点
                // 因此发现没有初始化，重新循环等待直到初始化完成
                if (t == null || h == null)
                    continue;

                // 队列为空或等待线程类型相同（不同类型才能匹配）
                // 这两种情况都要把当前线程加入到等待队列中
                if (h == t || t.isData == isData) {
                    QNode tn = t.next;
                    // tail对象已经被更新，出现不一致读的现象，重新循环
                    if (t != tail)
                        continue;
                    // 添加线程到等待队列时会先更新当前tail的next，然后
                    // 更新tail本身，因此出现只有next被更新的情况，应该
                    // 更新tail，然后重新循环
                    if (tn != null) {
                        advanceTail(t, tn);
                        continue;
                    }
                    // 设定了超时，剩余等待时间耗尽的时候，就无需再等待
                    if (timed && nanos <= 0)
                        return null;
                    // 首次使用s的时候，新建一个节点保存当前线程和数据来初始化s
                    if (s == null)
                        s = new QNode(e, isData);
                    // 尝试更新tail的next，把新建节点添加到tail的后面，如果失败了，就重新循环
                    if (!t.casNext(null, s))
                        continue;
                    // 把新建的节点设置为tail
                    advanceTail(t, s);
                    // 等待匹配线程，成功匹配则返回的匹配的值
                    // 否则返回当前节点，因此s和x相同表示请求被取消
                    Object x = awaitFulfill(s, e, timed, nanos);
                    if (x == s) {
                        clean(t, s);
                        return null;
                    }

                    // 这个时候已经匹配成功了，s应该是排在第一个的等待线程
                    // 如果s依然在队列中，那么需要更新head。
                    // 更新head的方法是把s这个排在第一位的节点作为新的head
                    // 因此需要重置一些属性使它变成虚拟节点
                    if (!s.isOffList()) {
                        advanceHead(t, s);
                        if (x != null)
                            s.item = s;
                        s.waiter = null;
                    }
                    // x不为null表示拿到匹配线程的数据（消费者拿到生产者的数据），
                    // 因此返回该数据，否则返回本身的数据（生成者返回自己的数据）
                    return (x != null) ? x : e;

                } else { // 线程可以匹配
                    // 因为是队列，因此匹配的是第一个节点
                    QNode m = h.next;
                    // 同样需要检查不一致读的情况
                    if (t != tail || m == null || h != head)
                        continue;

                    /** producer 和 consumer 匹配操作
                     *  1. 获取 m的 item (注意这里的m是head的next节点
                     *  2. 判断 isData 与x的模式是否匹配, 只有produce与consumer才能配成一对
                     *  3. x == m 判断是否 节点m 是否已经进行取消了, 具体看(QNOde#tryCancel)
                     *  4. m.casItem 将producer与consumer的数据进行交换 (这里存在并发时可能cas操作失败的情况)
                     *  5. 若 cas操作成功则将h节点dequeue
                     *
                     *  疑惑: 为什么将h进行 dequeue, 而不是 m节点
                     *  答案: 因为每次进行配对时, 都是将 h 是个 dummy node, 正真的数据节点 是 head.next
                     */
                    Object x = m.item;
                    // 匹配失败时，把m从队列中移走，重新循环
                    if (isData == (x != null) ||    // m已经被匹配了
                        x == m ||                   // m已经被取消了
                        !m.casItem(x, e)) {         // 用CAS设置m的数据为null
                        advanceHead(h, m);
                        continue;
                    }

                    // 匹配成功，更新head
                    advanceHead(h, m);
                    // 解除m的线程等待状态
                    LockSupport.unpark(m.waiter);
                    // 返回匹配的数据
                    return (x != null) ? x : e;
                }
            }
        }

```

OK, 我们梳理一下一般性的流程:

- 1. 一开始整个queue为空, 线程直接封装成QNode, 通过 awaitFulfill 方法进入自旋等待状态, 
除非超时或线程中断, 不然一直等待, 直到有线程与之匹配

- 2. 下个再来的线程若isData与尾节点一样,
 则进行第一步, 不然进行数据转移(步骤  advanceHead(h, m);   ), 然后 unpark 等待的线程

- 3. 等待的线程被唤醒, 从awaitFulfill方法返回, 最后将结果返回

 

接着来用于Unfair模式的TransferStack的transfer方法

大体逻辑应该是一样的，不同就是队列的入队和出队操作对应到栈时就是入栈和出栈的操作。

```java

        Object transfer(Object e, boolean timed, long nanos) {
            SNode s = null;
            int mode = (e == null) ? REQUEST : DATA;

            for (;;) {
                SNode h = head;
                // 栈为空或者节点类型相同的情况
                if (h == null || h.mode == mode) {
                    if (timed && nanos <= 0) {
                        // 检查栈顶节点是否已经取消，如果已经取消，弹出节点
                        // 重新循环，接着检查新的栈顶节点
                        if (h != null && h.isCancelled())
                            casHead(h, h.next);
                        else
                            return null;
                    // 新建节点，并且尝试把新节点入栈
                    } else if (casHead(h, s = snode(s, e, h, mode))) {
                        // 等待匹配，如果发现是被取消的情况，则释放节点，返回null
                        SNode m = awaitFulfill(s, timed, nanos);
                        if (m == s) {
                            clean(s);
                            return null;
                        }
                        // 如果匹配的成功两个节点是栈顶的两个节点
                        // 把这两个节点都弹出
                        if ((h = head) != null && h.next == s)
                            casHead(h, s.next);     // help s's fulfiller
                        return (mode == REQUEST) ? m.item : s.item;
                    }
                } else if (!isFulfilling(h.mode)) { // 栈顶节点没有和其他线程在匹配，可以匹配
                    if (h.isCancelled())            // 栈顶节点的请求已经被取消
                        casHead(h, h.next);         // 移除栈顶元素重新循环
                    // 尝试把该节点也入栈，该节点设置为正在匹配的状态
                    // 也就是isFulfilling返回true
                    else if (casHead(h, s=snode(s, e, h, FULFILLING|mode))) {
                        for (;;) {
                            // 栈顶节点（当前线程的节点）和它的下一个节点进行匹配，m为null意味着
                            // 栈里没有其他节点了，因为前面该节点入栈了，需要弹出这个节点重新循环
                            SNode m = s.next;
                            if (m == null) {
                                casHead(s, null);
                                s = null;
                                break;
                            }

                            // 这个时候是有节点可以匹配的，尝试为这两个节点做匹配
                            SNode mn = m.next;
                            // m和s匹配成功，弹出这两个节点，返回数据；匹配失败，把m移除
                            if (m.tryMatch(s)) {
                                casHead(s, mn);
                                return (mode == REQUEST) ? m.item : s.item;
                            } else
                                s.casNext(m, mn);
                        }
                    }
                // 栈顶正在匹配，参见代码：
                // else if (casHead(h, s=snode(s, e, h, FULFILLING|mode))) {
                // 做法基本类似，只是这里帮助其他线程匹配，无论成功与否
                // 都要重新循环
                } else {
                    SNode m = h.next;               
                    if (m == null)
                        casHead(h, null);
                    else {
                        SNode mn = m.next;
                        if (m.tryMatch(h))
                            casHead(h, mn);
                        else
                            h.casNext(m, mn);
                    }
                }
            }
        }

```

### 公平模式 TransferQueue awaitFulfill

```java
/**
 * Spins/blocks until node s is fulfilled
 *
 * 主逻辑: 若节点是 head.next 则进行 spins 一会, 若不是, 则调用 LockSupport.park / parkNanos(), 直到其他的线程对其进行唤醒
 *
 * @param s the waiting node
 * @param e the comparsion value for checking match
 * @param timed true if timed wait
 * @param nanos timeout value
 * @return  matched item, or s of cancelled
 */
Object awaitFulfill(QNode s, E e, boolean timed, long nanos){

    final long deadline = timed ? System.nanoTime() + nanos : 0L;// 1. 计算 deadline 时间 (只有 timed 为true 时才有用)
    Thread w = Thread.currentThread();   // 2. 获取当前的线程
    int spins = ((head.next == s) ?        // 3. 若当前节点是 head.next 时才进行 spin, 不然的话不是浪费 CPU 吗, 对挖
            (timed ? maxTimeSpins : maxUntimedSpins) : 0);
    for(;;){                                        // loop 直到 成功
        if(w.isInterrupted()){                      // 4. 若线程中断, 直接将 item = this, 在 transfer 中会对返回值进行判断 (transfer中的 步骤 11)
            s.tryCancel(e);
        }
        Object x = s.item;
        if(x != e){                                 // 5. 在进行线程阻塞->唤醒, 线程中断, 等待超时, 这时 x != e,直接return 回去
            return x;
        }
        if(timed){
            nanos = deadline - System.nanoTime();
            if(nanos <= 0L){                        // 6. 等待超时, 改变 node 的item值, 进行 continue, 下一步就到  awaitFulfill的第 5 步 -> return
                s.tryCancel(e);
                continue;
            }
        }
        if(spins > 0){                             // 7. spin 一次一次减少
            --spins;
        }
        else if(s.waiter == null){
            s.waiter = w;
        }
        else if(!timed){                           // 8. 进行没有超时的 park
            LockSupport.park(this);
        }
        else if(nanos > spinForTimeoutThreshold){  // 9. 自旋次数过了, 直接 + timeout 方式 park
            LockSupport.parkNanos(this, nanos);
        }
    }
}

```

梳理逻辑:

- 1. 计算timeout时间(若 time = true)

- 2. 判断 当前节点是否是 head.next 节点(queue中有个dummy node 的存在, AQS 中也是这样), 
若是的话就进行 spin 的赋值, 其他的节点没有这个需要, 浪费资源

- 3. 接下来就是自旋, 超过次数就进行阻塞, 直到有其他线程唤醒, 或线程中断(这里线程中断返回的是 Node 自己)

### 公平模式 TransferQueue clean
```java
/**
 * Gets rid of cancelled node s with original predecessor pred.
 * 对 中断的 或 等待超时的 节点进行清除操作
 */
void clean(QNode pred, QNode s) {
    s.waiter = null; // forget thread                                        // 1. 清除掉 thread 引用
    /*
     * At any given time, exactly one node on list cannot be
     * deleted -- the last inserted node. To accommodate this,
     * if we cannot delete s, we save its predecessor as
     * "cleanMe", deleting the previously saved version
     * first. At least one of node s or the node previously
     * saved can always be deleted, so this always terminates.
     *
     * 在程序运行中的任何时刻, 最后插入的节点不能被删除(这里的删除指 通过 cas 直接删除, 因为这样直接删除会有多删除其他节点的风险)
     * 当 节点 s 是最后一个节点时, 将 s.pred 保存为 cleamMe 节点, 下次再进行清除操作
     */
    while (pred.next == s) { // Return early if already unlinked           // 2. 判断 pred.next == s, 下面的 步骤2 可能导致 pred.next = next
        QNode h = head;
        QNode hn = h.next;   // Absorb cancelled first node as head
        if (hn != null && hn.isCancelled()) {                              // 3. hn  中断或者超时, 则推进 head 指针, 若这时 h 是 pred 则 loop 中的条件 "pred.next == s" 不满足, 退出 loop
            advanceHead(h, hn);
            continue;
        }
        QNode t = tail;      // Ensure consistent read for tail
        if (t == h)                                                        // 4. 队列为空, 说明其他的线程进行操作, 删除了 节点(注意这里永远会有个 dummy node)
            return;
        QNode tn = t.next;
        if (t != tail)                                                    // 5. 其他的线程改变了 tail, continue 重新来
            continue;
        if (tn != null) {
            advanceTail(t, tn);                                            // 6. 帮助推进 tail
            continue;
        }
        if (s != t) {        // If not tail, try to unsplice              // 7. 节点 s 不是尾节点, 则 直接 CAS 删除节点(在队列中间进行这种删除是没有风险的)
            QNode sn = s.next;
            if (sn == s || pred.casNext(s, sn))
                return;
        }

        QNode dp = cleanMe;                                             // 8. s 是队列的尾节点, 则 cleanMe 出场
        if (dp != null) {    // Try unlinking previous cancelled node
            QNode d = dp.next;                                          // 9. cleanMe 不为 null, 进行删除删一次的 s节点, 也就是这里的节点d
            QNode dn;
            if (d == null ||               // d is gone or              // 10. 这里有几个特殊情况 1. 原来的s节点()也就是这里的节点d已经删除; 2. 原来的节点 cleanMe 已经通过 advanceHead 进行删除; 3 原来的节点 s已经删除 (所以 !d.siCancelled), 存在这三种情况, 直接将 cleanMe 清除
                    d == dp ||                 // d is off list or
                    !d.isCancelled() ||        // d not cancelled or
                    (d != t &&                 // d not tail and        // 11. d 不是tail节点, 且dn没有offlist, 直接通过 cas 删除 上次的节点 s (也就是这里的节点d); 其实就是根据 cleanMe 来清除队列中间的节点
                            (dn = d.next) != null &&  //   has successor
                            dn != d &&                //   that is on list
                            dp.casNext(d, dn)))       // d unspliced
                casCleanMe(dp, null);                                  // 12. 清除 cleanMe 节点, 这里的 dp == pred 若成立, 说明清除节点s， 成功, 直接 return, 不然的话要再次 loop, 接着到 步骤 13, 设置这次的 cleanMe 然后再返回
            if (dp == pred)
                return;      // s is already saved node
        } else if (casCleanMe(null, pred))                          // 原来的 cleanMe 是 null, 则将 pred 标记为 cleamMe 为下次 清除 s 节点做标识
            return;          // Postpone cleaning s
    }
}

```

clean 方法是 整个代码分析过程中的难点：

- 1. 难在并发的情况比较多

- 2. cleanMe 节点存在的意义

调用这个方法都是由 节点线程中断或等待超时时调用的, 清除时分两种情况讨论:

- 1.删除的节点不是queue尾节点, 这时 直接 pred.casNext(s, s.next) 方式来进行删除(和ConcurrentLikedQueue中差不多)

- 2.删除的节点是队尾节点
  - 1)此时 cleanMe == null, 则 前继节点pred标记为 cleanMe, 为下次删除做准备
  
  - 2)此时 cleanMe != null, 先删除上次需要删除的节点, 然后将 cleanMe至null, 让后再将 pred 赋值给 cleanMe
这时我们想起了 ConcurrentSkipListMap 中的 marker 节点, 对, marker 和 cleanMe 都是起着防止并发环境中多删除节点的功能
 
 
TransferQueue和TransferStack的算法实现可以参考 [这里](http://www.cs.rochester.edu/research/synchronization/pseudocode/duals.html)